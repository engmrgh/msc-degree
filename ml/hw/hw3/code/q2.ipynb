{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><h3>HW3, Question 2</h3></div>\n",
    "<div align=\"center\"><h5>Mohammadreza Ghofrani, 400131076</h5></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn import *\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "pd.options.plotting.backend = \"plotly\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/data_train.csv', header=None)\n",
    "test = pd.read_csv('data/data_test.csv', header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Global constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABLE_COLUMN = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest = list()\n",
    "features = list(train.columns)\n",
    "features.remove(LABLE_COLUMN)\n",
    "for i in range(15):\n",
    "    f1, f2, f3 = np.random.choice(features, 3, replace=False)\n",
    "    tree_clf = sklearn.tree.DecisionTreeClassifier(max_depth=3)\n",
    "    tree_clf.fit(train[[f1,f2,f3]], train[LABLE_COLUMN])\n",
    "    random_forest.append((tree_clf, (f1,f2,f3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t\tRandom Forest Classifier Results\n",
      "Accuracy: 0.6481\n",
      "Precision: 0.6643\n",
      "Confusion Matrix:\n",
      " [[307   0  12   0   3   0  41   0   0   0]\n",
      " [  0 133 128  94   7   0   1   1   0   0]\n",
      " [  0   1 333  27   1   0   0   2   0   0]\n",
      " [  0   3   0 332   1   0   0   0   0   0]\n",
      " [  0   0   3  10 350   0   1   0   0   0]\n",
      " [  1   0   2 163   2 166   0   0   1   0]\n",
      " [  2   0   1   2   0   0 328   3   0   0]\n",
      " [  0  22  11  19  28   3  34 246   1   0]\n",
      " [ 69   0  15   1   0  80  96   3  72   0]\n",
      " [  0   8   0 262  63   0   2   0   1   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/engmrgh/university/1th_semester/venv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# True Lables\n",
    "y_true = list()\n",
    "y_true = test[LABLE_COLUMN]\n",
    "\n",
    "# Predicting using Random Forest\n",
    "voting_box = np.zeros((len(test), len(set(y_true))))\n",
    "for clf, features in random_forest:\n",
    "    clf_prediction = clf.predict(test[list(features)])\n",
    "    for i, p in enumerate(clf_prediction):\n",
    "        voting_box[i][p] += 1\n",
    "y_pred = list()\n",
    "for instance in voting_box:\n",
    "    y_pred.append(np.argmax(instance))\n",
    "\n",
    "print(f\"\\t\\t\\tRandom Forest Classifier Results\")\n",
    "print(f\"Accuracy: {sklearn.metrics.accuracy_score(y_true, y_pred):.4f}\")\n",
    "print(f\"Precision: {sklearn.metrics.precision_score(y_true, y_pred, average='macro'):.4f}\")\n",
    "print(f\"Confusion Matrix:\\n {sklearn.metrics.confusion_matrix(y_true, y_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest = sklearn.ensemble.RandomForestClassifier(n_estimators=15, max_depth=3, random_state=0, max_features=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(test.loc[:, test.columns != LABLE_COLUMN])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Adaboost classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(n_estimators=10)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = sklearn.ensemble.AdaBoostClassifier(n_estimators=10)\n",
    "clf.fit(train.loc[:, train.columns != LABLE_COLUMN], train[LABLE_COLUMN])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t\tAdaboost Tree Classifier Results\n",
      "Accuracy: 0.5486\n",
      "Precision: 0.6366\n",
      "Confusion Matrix:\n",
      " [[298   0   1   0   0   0  62   2   0   0]\n",
      " [  0 215 143   0   0   0   1   1   0   4]\n",
      " [  0   8 330   4   0   0  13   8   0   1]\n",
      " [  0   2 328   4   0   0   0   1   0   1]\n",
      " [  0   0   0   0 327   0  18   0   0  19]\n",
      " [  7   5  75  48   2   4  31 132   0  31]\n",
      " [  1   0   8   0   1   0 313  11   0   2]\n",
      " [  0  31  12   2   0   0   0 297   0  22]\n",
      " [ 59   0   1   0   0   1 104 150  21   0]\n",
      " [  0  13 186  12  12   0   2   1   0 110]]\n"
     ]
    }
   ],
   "source": [
    "y_true = test[LABLE_COLUMN]\n",
    "y_pred = clf.predict(test.loc[:, test.columns != LABLE_COLUMN])\n",
    "\n",
    "print(f\"\\t\\t\\tAdaboost Tree Classifier Results\")\n",
    "print(f\"Accuracy: {sklearn.metrics.accuracy_score(y_true, y_pred):.4f}\")\n",
    "print(f\"Precision: {sklearn.metrics.precision_score(y_true, y_pred, average='macro'):.4f}\")\n",
    "print(f\"Confusion Matrix:\\n {sklearn.metrics.confusion_matrix(y_true, y_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training with 5, 20 and 50 classifiers and reporting the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t\tAdaboost Tree Classifier Results with 5 number of estimators\n",
      "Accuracy: 0.5234\n",
      "Precision: 0.5487\n",
      "Confusion Matrix:\n",
      " [[328   0   1   1   1   0  25   0   7   0]\n",
      " [  0 135 216   3   9   0   1   0   0   0]\n",
      " [  0   0 338   5   0   0  13   8   0   0]\n",
      " [  0   2 329   4   0   0   0   0   0   1]\n",
      " [  0   5   0   3 336   0  18   0   0   2]\n",
      " [166   5  75  84   3   0   0   0   1   1]\n",
      " [  9   0   8   5   5   0 297  12   0   0]\n",
      " [  3  57  17   5  23   0   0 250   5   4]\n",
      " [165   0   2   0   1   0   1  63 104   0]\n",
      " [  0  33 188  41  34   0   0   0   1  39]]\n",
      "\n",
      "\t\t\tAdaboost Tree Classifier Results with 20 number of estimators\n",
      "Accuracy: 0.6369\n",
      "Precision: 0.6388\n",
      "Confusion Matrix:\n",
      " [[323   0   1   0   1   0  26   0  12   0]\n",
      " [  0 207 138   5   0   0   2   0   0  12]\n",
      " [  0   8 334   1   0   0  13   8   0   0]\n",
      " [  0   2  60 245   0  19   9   0   0   1]\n",
      " [  1   9   3   0 324   0  19   0   0   8]\n",
      " [165  12   0 119   2  11  15   1   2   8]\n",
      " [  0   0   0   8   0   0 320   5   1   2]\n",
      " [  0  31  12   2   0   0   9 281   7  22]\n",
      " [184   0  11   0   0   0   6  32 103   0]\n",
      " [  0  16   9 168  12  30  20   0   1  80]]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/engmrgh/university/1th_semester/venv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t\tAdaboost Tree Classifier Results with 50 number of estimators\n",
      "Accuracy: 0.6103\n",
      "Precision: 0.5906\n",
      "Confusion Matrix:\n",
      " [[336   0   1   0   0   0  23   0   3   0]\n",
      " [  0 212 138   5   4   0   2   0   0   3]\n",
      " [  0   8 334   1   0   0  13   8   0   0]\n",
      " [  0   2  60 245   0  19   9   0   0   1]\n",
      " [  1   9   3   0 325   0  19   0   0   7]\n",
      " [166  12   0 119   2  11  15   0   2   8]\n",
      " [  0   0   0   8   0   0 308   5  13   2]\n",
      " [  0  31  12   2   0   0   9 270  18  22]\n",
      " [264   0  10   0   0   0  12  28  22   0]\n",
      " [  1  24   9 168  12  30  20   0   0  72]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for n_estimators in [5, 20, 50]:\n",
    "    clf = sklearn.ensemble.AdaBoostClassifier(n_estimators=n_estimators)\n",
    "    clf.fit(train.loc[:, train.columns != LABLE_COLUMN], train[LABLE_COLUMN])\n",
    "    y_true = test[LABLE_COLUMN]\n",
    "    y_pred = clf.predict(test.loc[:, test.columns != LABLE_COLUMN])\n",
    "\n",
    "    print(f\"\\t\\t\\tAdaboost Tree Classifier Results with {n_estimators} number of estimators\")\n",
    "    print(f\"Accuracy: {sklearn.metrics.accuracy_score(y_true, y_pred):.4f}\")\n",
    "    print(f\"Precision: {sklearn.metrics.precision_score(y_true, y_pred, average='macro'):.4f}\")\n",
    "    print(f\"Confusion Matrix:\\n {sklearn.metrics.confusion_matrix(y_true, y_pred)}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None,\n",
       "                                     enable_categorical=False,\n",
       "                                     eval_metric='mlogloss', gamma=None,\n",
       "                                     gpu_id=None, importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None, max_delta_step=None,\n",
       "                                     max_depth=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone...\n",
       "                                     num_parallel_tree=None,\n",
       "                                     objective='multi:softmax', predictor=None,\n",
       "                                     random_state=None, reg_alpha=None,\n",
       "                                     reg_lambda=None, scale_pos_weight=None,\n",
       "                                     subsample=None, tree_method=None,\n",
       "                                     use_label_encoder=False, ...),\n",
       "             n_jobs=5,\n",
       "             param_grid={'learning_rate': [0.1, 0.01, 0.001],\n",
       "                         'max_depth': range(3, 10, 2),\n",
       "                         'min_split_loss': range(1, 10, 3),\n",
       "                         'n_estimators': range(10, 30, 10)},\n",
       "             verbose=True)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtrain = xgb.DMatrix(train.iloc[:, train.columns!=LABLE_COLUMN], label=train[LABLE_COLUMN])\n",
    "dtest = xgb.DMatrix(test.iloc[:, test.columns!=LABLE_COLUMN], label=test[LABLE_COLUMN])\n",
    "\n",
    "estimator = xgb.XGBClassifier(objective= 'multi:softmax', nthread=4, use_label_encoder=False, eval_metric='mlogloss')\n",
    "\n",
    "parameters = {\n",
    "    'max_depth': range (2, 10, 2),\n",
    "    'n_estimators': range(10, 30, 10),\n",
    "    'learning_rate': [0.1, 0.01, 0.001],\n",
    "    'min_split_loss': range(1, 10, 3),\n",
    "    'max_depth': range(3, 10, 2)\n",
    "}\n",
    "\n",
    "grid_search = sklearn.model_selection.GridSearchCV(estimator=estimator, param_grid=parameters, n_jobs = 5)\n",
    "grid_search.fit(train.loc[:, train.columns != LABLE_COLUMN], train[LABLE_COLUMN])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t\tXG Boost Results\n",
      "Accuracy: 0.9443\n",
      "Precision: 0.9454\n",
      "Confusion Matrix:\n",
      " [[342   1   0   0   0   0   0   0  20   0]\n",
      " [  0 321  40   0   0   0   0   2   0   1]\n",
      " [  0   4 354   3   0   0   1   2   0   0]\n",
      " [  0   4   0 330   0   0   0   1   0   1]\n",
      " [  0   2   0   0 357   4   0   0   0   1]\n",
      " [  0   0   0   7   0 288   1   0   3  36]\n",
      " [  0   1   0   0   0   4 331   0   0   0]\n",
      " [  0  10   1   3  16   0   1 333   0   0]\n",
      " [  1   0   0   0   0   0   0   0 335   0]\n",
      " [  0   6   0   9   0   6   0   2   1 312]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_estimator = grid_search.best_estimator_\n",
    "best_estimator.fit(train.loc[:, train.columns != LABLE_COLUMN], train[LABLE_COLUMN])\n",
    "y_true = test[LABLE_COLUMN]\n",
    "y_pred = best_estimator.predict(test.loc[:, test.columns != LABLE_COLUMN])\n",
    "\n",
    "print(f\"\\t\\t\\tXG Boost Results\")\n",
    "print(f\"Accuracy: {sklearn.metrics.accuracy_score(y_true, y_pred):.4f}\")\n",
    "print(f\"Precision: {sklearn.metrics.precision_score(y_true, y_pred, average='macro'):.4f}\")\n",
    "print(f\"Confusion Matrix:\\n {sklearn.metrics.confusion_matrix(y_true, y_pred)}\")\n",
    "print()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9b6a0ed5024aaea3e9c9718cd433ea4f81c4a83155ee8373e4054333975ec784"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
